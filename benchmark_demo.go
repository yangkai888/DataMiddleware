package main

import (
	"fmt"
	"sync"
	"sync/atomic"
	"time"

	"datamiddleware/internal/benchmark"
	"datamiddleware/internal/cache"
	"datamiddleware/internal/config"
	"datamiddleware/internal/logger"
	"datamiddleware/pkg/types"
)

func main() {
	// åˆå§‹åŒ–æ—¥å¿—
	log, err := logger.Init(types.LoggerConfig{
		Level:  "info",
		Format: "console",
		Output: "stdout",
	})
	if err != nil {
		fmt.Printf("æ—¥å¿—åˆå§‹åŒ–å¤±è´¥: %v\n", err)
		return
	}

	fmt.Println("å¼€å§‹æ€§èƒ½æµ‹è¯•å¥—ä»¶æ¼”ç¤º...")

	// åˆå§‹åŒ–é…ç½®
	cfg, err := config.Init()
	if err != nil {
		fmt.Printf("é…ç½®åˆå§‹åŒ–å¤±è´¥: %v\n", err)
		return
	}

	// åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
	cacheManager, err := cache.NewManager(cfg.Cache, log)
	if err != nil {
		fmt.Printf("ç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: %v\n", err)
		return
	}
	defer cacheManager.Close()

	// æµ‹è¯•1: ç¼“å­˜åŸºå‡†æµ‹è¯•
	fmt.Println("\n=== æµ‹è¯•1: ç¼“å­˜åŸºå‡†æµ‹è¯• ===")

	benchConfig := benchmark.BenchmarkConfig{
		Concurrency:     10,
		Duration:        3 * time.Second,
		RequestInterval: 100 * time.Millisecond,
		WarmupDuration:  500 * time.Millisecond,
		Verbose:         false,
	}

	runner := benchmark.NewBenchmarkRunner(benchConfig, log)

	fmt.Printf("å¼€å§‹ç¼“å­˜åŸºå‡†æµ‹è¯•: å¹¶å‘æ•°=%d, æŒç»­æ—¶é—´=%v\n",
		benchConfig.Concurrency, benchConfig.Duration)

	cacheResult, err := runner.RunCacheBenchmark(cacheManager)
	if err != nil {
		fmt.Printf("ç¼“å­˜åŸºå‡†æµ‹è¯•å¤±è´¥: %v\n", err)
		return
	}

	fmt.Printf("ç¼“å­˜æµ‹è¯•ç»“æœ:\n")
	fmt.Printf("  æ€»è¯·æ±‚æ•°: %d\n", cacheResult.TotalRequests)
	fmt.Printf("  æˆåŠŸè¯·æ±‚: %d\n", cacheResult.SuccessRequests)
	fmt.Printf("  å¤±è´¥è¯·æ±‚: %d\n", cacheResult.FailedRequests)
	fmt.Printf("  QPS: %.2f\n", cacheResult.QPS)
	fmt.Printf("  å¹³å‡å“åº”æ—¶é—´: %v\n", cacheResult.AvgResponseTime)
	fmt.Printf("  å†…å­˜ä½¿ç”¨: %d MB\n", cacheResult.MemoryStats.Alloc/1024/1024)

	// æµ‹è¯•2: ç®€å•å‹åŠ›æµ‹è¯•æ¼”ç¤º
	fmt.Println("\n=== æµ‹è¯•2: ç®€å•å‹åŠ›æµ‹è¯•æ¼”ç¤º ===")

	fmt.Println("æ¼”ç¤ºåŸºæœ¬çš„å‹åŠ›æµ‹è¯•æ¦‚å¿µ...")

	// ç®€å•çš„å¹¶å‘æµ‹è¯•
	concurrency := 20
	requestsPerWorker := 50

	fmt.Printf("å¹¶å‘æ•°: %d, æ¯ä¸ªå·¥ä½œåç¨‹è¯·æ±‚æ•°: %d\n", concurrency, requestsPerWorker)

	var totalRequests int64
	var totalTime time.Duration

	start := time.Now()

	// å¯åŠ¨å¤šä¸ªåç¨‹è¿›è¡Œæµ‹è¯•
	var wg sync.WaitGroup
	for i := 0; i < concurrency; i++ {
		wg.Add(1)
		go func(workerID int) {
			defer wg.Done()

			for j := 0; j < requestsPerWorker; j++ {
				key := fmt.Sprintf("test_key_%d_%d", workerID, j)
				value := []byte(fmt.Sprintf("test_value_%d_%d", workerID, time.Now().UnixNano()))

				// æ‰§è¡Œç¼“å­˜æ“ä½œ
				cacheManager.Set(key, value)
				atomic.AddInt64(&totalRequests, 1)
			}
		}(i)
	}

	wg.Wait()
	totalTime = time.Since(start)

	qps := float64(totalRequests) / totalTime.Seconds()
	fmt.Printf("æµ‹è¯•å®Œæˆ:\n")
	fmt.Printf("  æ€»è¯·æ±‚æ•°: %d\n", totalRequests)
	fmt.Printf("  æ€»æ—¶é—´: %v\n", totalTime)
	fmt.Printf("  QPS: %.2f\n", qps)

	// æµ‹è¯•3: æ€§èƒ½å¯¹æ¯”æµ‹è¯•
	fmt.Println("\n=== æµ‹è¯•3: æ€§èƒ½å¯¹æ¯”æµ‹è¯• ===")

	fmt.Println("å¯¹æ¯”ä¸åŒå¹¶å‘åº¦ä¸‹çš„ç¼“å­˜æ€§èƒ½...")

	concurrencies := []int{5, 10, 20}

	for _, conc := range concurrencies {
		fmt.Printf("\næµ‹è¯•å¹¶å‘æ•°: %d\n", conc)

		config := benchmark.BenchmarkConfig{
			Concurrency:     conc,
			Duration:        2 * time.Second,
			RequestInterval: time.Duration(1000/conc) * time.Millisecond, // åŠ¨æ€è°ƒæ•´é—´éš”
			WarmupDuration:  200 * time.Millisecond,
			Verbose:         false,
		}

		testRunner := benchmark.NewBenchmarkRunner(config, log)
		result, err := testRunner.RunCacheBenchmark(cacheManager)
		if err != nil {
			fmt.Printf("  æµ‹è¯•å¤±è´¥: %v\n", err)
			continue
		}

		fmt.Printf("  QPS: %.2f\n", result.QPS)
		fmt.Printf("  å¹³å‡å“åº”æ—¶é—´: %v\n", result.AvgResponseTime)
	}

	fmt.Println("\nğŸ‰ æ€§èƒ½æµ‹è¯•å¥—ä»¶æ¼”ç¤ºå…¨éƒ¨å®Œæˆï¼")
}
